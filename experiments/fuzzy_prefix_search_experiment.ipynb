{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V1 - with only documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install python-Levenshtein\n",
    "import pandas as pd\n",
    "import Levenshtein as ln\n",
    "import networkx as nx\n",
    "from ast import literal_eval\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "#G = nx.DiGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████| 1563052/1563052 [00:01<00:00, 836118.76it/s]\n"
     ]
    }
   ],
   "source": [
    "ids_question_map = {}\n",
    "question_ids_map = {}\n",
    "nline = 0\n",
    "\n",
    "with open(\"../data/qg.txt\", \"r\") as f:\n",
    "    with tqdm(total=1563052) as progress_bar:\n",
    "        while line := f.readline():\n",
    "            ids_question_map[nline] = line.strip('\\n').lower()\n",
    "            question_ids_map[line.strip('\\n').lower()] = nline\n",
    "            nline += 1\n",
    "            progress_bar.update(1)\n",
    "\n",
    "pickle.dump(ids_question_map, open(\"../index/ids_question_map.pkl\", \"wb\"))\n",
    "pickle.dump(question_ids_map, open(\"../index/question_ids_map.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████▉| 1562895/1563052 [00:56<00:00, 27455.25it/s]\n"
     ]
    }
   ],
   "source": [
    "ids_question_map = pickle.load(open(\"../index/ids_question_map.pkl\", \"rb\"))\n",
    "question_ids_map = pickle.load(open(\"../index/question_ids_map.pkl\", \"rb\"))\n",
    "\n",
    "G = nx.DiGraph()\n",
    "\n",
    "track_leafs = {}\n",
    "\n",
    "with open(\"../data/qg.txt\", \"r\") as f:\n",
    "    nlines = 0 \n",
    "    with tqdm(total=1563052) as progress_bar:\n",
    "        while line := f.readline():\n",
    "            if line!='':\n",
    "                question = line.strip(\"\\n\").lower()\n",
    "                tokenized = question.split()\n",
    "\n",
    "                if not tokenized:\n",
    "                    continue\n",
    "\n",
    "                prev_node_entry = tokenized[0]\n",
    "                for i in range(2, len(tokenized)+1):\n",
    "                    if len(prev_node_entry.split()) == 1:\n",
    "                        if prev_node_entry not in G:\n",
    "                            G.add_node(prev_node_entry, starts=True)\n",
    "                        else:\n",
    "                            G.nodes[prev_node_entry]['starts'] = True\n",
    "                    else:\n",
    "                        if prev_node_entry not in G:\n",
    "                            G.add_node(prev_node_entry, starts=False)\n",
    "                        else:\n",
    "                            G.nodes[prev_node_entry]['starts'] = False\n",
    "\n",
    "                    #if \" \".join(tokenized[:i]) not in G:\n",
    "                    if len(\" \".join(tokenized[:i]).split()) == 1:\n",
    "                        if \" \".join(tokenized[:i]) not in G:\n",
    "                            G.add_node(\" \".join(tokenized[:i]), starts=True)\n",
    "                        else:\n",
    "                            G.nodes[\" \".join(tokenized[:i])]['starts'] = True\n",
    "                    else:\n",
    "                        if \" \".join(tokenized[:i]) not in G:\n",
    "                            G.add_node(\" \".join(tokenized[:i]), starts=False)\n",
    "                        else:\n",
    "                            G.nodes[\" \".join(tokenized[:i])]['starts'] = False\n",
    "\n",
    "                    #G.nodes[prev_node_entry]['leaf'] = G.nodes[prev_node_entry].get('leaf', []) + [question_ids_map[question]]\n",
    "                    #print(prev_node_entry, question)\n",
    "                    a = track_leafs.get(prev_node_entry, [])\n",
    "                    a.append(question_ids_map[question])\n",
    "                    track_leafs[prev_node_entry] = a\n",
    "                    G.add_edge(prev_node_entry, \" \".join(tokenized[:i]))\n",
    "                    prev_node_entry =  \" \".join(tokenized[:i])\n",
    "                a = track_leafs.get(question, [])\n",
    "                a.append(question_ids_map[question])\n",
    "                track_leafs[question] = a\n",
    "                    \n",
    "            progress_bar.update(1)\n",
    "\n",
    "roots_list = [i for i,j in G.nodes(data=\"starts\", default=1) if j==True]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gpickle(G, \"../index/query_graph.gpickle\")\n",
    "pickle.dump(track_leafs, open(\"../index/track_leafs.pkl\", \"wb\"))\n",
    "# G = nx.read_gpickle(\"../index/query_graph.gpickle\")\n",
    "# track_leafs = pickle.load(open(\"../index/track_leafs.pkl\", \"rb\"))\n",
    "# roots_list = [i for i,j in G.nodes(data=\"starts\", default=1) if j==True]\n",
    "\n",
    "# ids_question_map = pickle.load(open(\"../index/ids_question_map.pkl\", \"rb\"))\n",
    "# question_ids_map = pickle.load(open(\"../index/question_ids_map.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken:  0.018978670999786118\n"
     ]
    }
   ],
   "source": [
    "# recursion\n",
    "import timeit\n",
    "\n",
    "\n",
    "#query = \"hwat ia the bst way to file\".lower()\n",
    "#query = \"becoming a\"\n",
    "query = \"do parents\".lower()\n",
    "#query = \"hwat ia the\".lower()\n",
    "#query = \"which is the difference between bile\".lower()\n",
    "#query = \"what was the name given to a\".lower()\n",
    "#query = \"bbilical defi\".lower()\n",
    "tokenized_query = query.split()\n",
    "len_tokenized_query = len(tokenized_query)\n",
    "node_list = []\n",
    "def recurssive_search(comparison_term, G, idx=1, root=False, node_list=[], forked=False):\n",
    "    new_term = []\n",
    "    for node in (roots_list if root else G[\" \".join(comparison_term.split()[:-1])]):\n",
    "        \n",
    "        # don't auto-correct on last-word\n",
    "        if ((ln.distance(comparison_term, node) <= 2) if idx!=len_tokenized_query-1 else tokenized_query[-1] in node):\n",
    "            if idx!=len_tokenized_query-1:\n",
    "                node_list.extend(recurssive_search(node + \" \" + tokenized_query[idx+1], G, idx+1, root=False, node_list=node_list, forked=True))\n",
    "            else:\n",
    "                if node in G and node in track_leafs:\n",
    "                    new_term.append(node)\n",
    "\n",
    "              \n",
    "    if forked:\n",
    "        if idx==len_tokenized_query-1:\n",
    "            return [ids_question_map[child] for term in new_term for child in track_leafs[term]]\n",
    "            \n",
    "        return \"\"\n",
    "    else:\n",
    "        if len(tokenized_query)==1:\n",
    "            if idx==len_tokenized_query-1:\n",
    "                return [ids_question_map[child] for term in new_term for child in track_leafs[term]]\n",
    "        return node_list\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "res = recurssive_search(tokenized_query[0], G, idx=0, root=True)\n",
    "print(\"Total time taken: \", timeit.default_timer()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ln.distance(\"machine\", \"mcine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['how parents talk to teenagers on sexual health issues',\n",
       " 'how parents influence their children to start smoking',\n",
       " 'how parents determine their own development',\n",
       " 'how parents should be held responsible',\n",
       " 'how parents should not be accountable for their children behavior',\n",
       " 'how grandparents help',\n",
       " 'how grandparents can help grandchildren',\n",
       " 'how grandparents help one another',\n",
       " 'how grandparents care for grandchildren in different ways',\n",
       " 'how grandparents benefit from the adoption act',\n",
       " 'how grandparents are benefiting from the foster care and adoption act',\n",
       " 'how grandparents care for their grandchildren',\n",
       " 'do grandparents really care what their grandchildren do',\n",
       " 'do grandparents help each other',\n",
       " 'do grandparents really love to read to grandchildren',\n",
       " 'do grandparents help grandchildren',\n",
       " 'do grandparents love their grandchildren for the love they give them',\n",
       " 'do parents influence baby eye color',\n",
       " 'do parents know what to do when their kid has a fever',\n",
       " 'do parents need to have a child for family leave',\n",
       " 'is grandparents dead in beach city tx',\n",
       " 'does grandparents help each other emotionally',\n",
       " 'does grandparents ever cry']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V2 - documents & user queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import Levenshtein as ln\n",
    "import networkx as nx\n",
    "from ast import literal_eval\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's load v1 data\n",
    "\n",
    "G = nx.read_gpickle(\"../index/query_graph.gpickle\")\n",
    "track_leafs = pickle.load(open(\"../index/track_leafs.pkl\", \"rb\"))\n",
    "roots_list = [i for i,j in G.nodes(data=\"starts\", default=1) if j==True]\n",
    "\n",
    "ids_question_map = pickle.load(open(\"../index/ids_question_map.pkl\", \"rb\"))\n",
    "question_ids_map = pickle.load(open(\"../index/question_ids_map.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "808731"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import sys\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "\n",
    "old_lines = len(ids_question_map)\n",
    "lines = len(ids_question_map)\n",
    "with open(\"../data/queries.train.tsv\", \"r\") as f:\n",
    "    tsv_reader = csv.reader(f, delimiter=\"\\t\")\n",
    "    for row in tsv_reader:\n",
    "        ids_question_map[lines] = row[-1].lower()\n",
    "        question_ids_map[row[-1].lower()] = lines\n",
    "        lines += 1\n",
    "lines - old_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1563277"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_ids_map['do parents go to their kids college orientation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████| 808731/808731 [00:30<00:00, 26348.01it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(\"../data/queries.train.tsv\", \"r\") as f:\n",
    "    tsv_reader = csv.reader(f, delimiter=\"\\t\")\n",
    "    nlines = 0 \n",
    "    for row in tqdm(tsv_reader, total=808731):\n",
    "        nlines+=1\n",
    "        line = row[-1]\n",
    "        if line!='':\n",
    "            question = line.strip(\"\\n\").lower()\n",
    "            tokenized = question.split()\n",
    "\n",
    "            if not tokenized:\n",
    "                continue\n",
    "            \n",
    "            prev_node_entry = tokenized[0]\n",
    "            for i in range(2, len(tokenized)+1):\n",
    "                if len(prev_node_entry.split()) == 1:\n",
    "                    if prev_node_entry not in G:\n",
    "                        G.add_node(prev_node_entry, starts=True)\n",
    "                    else:\n",
    "                        G.nodes[prev_node_entry]['starts'] = True\n",
    "                else:\n",
    "                    if prev_node_entry not in G:\n",
    "                        G.add_node(prev_node_entry, starts=False)\n",
    "                    else:\n",
    "                        G.nodes[prev_node_entry]['starts'] = False\n",
    "\n",
    "                #if \" \".join(tokenized[:i]) not in G:\n",
    "                if len(\" \".join(tokenized[:i]).split()) == 1:\n",
    "                    if \" \".join(tokenized[:i]) not in G:\n",
    "                        G.add_node(\" \".join(tokenized[:i]), starts=True)\n",
    "                    else:\n",
    "                        G.nodes[\" \".join(tokenized[:i])]['starts'] = True\n",
    "                else:\n",
    "                    if \" \".join(tokenized[:i]) not in G:\n",
    "                        G.add_node(\" \".join(tokenized[:i]), starts=False)\n",
    "                    else:\n",
    "                        G.nodes[\" \".join(tokenized[:i])]['starts'] = False\n",
    "\n",
    "                #G.nodes[prev_node_entry]['leaf'] = G.nodes[prev_node_entry].get('leaf', []) + [question_ids_map[question]]\n",
    "                #print(prev_node_entry, question)\n",
    "                a = track_leafs.get(prev_node_entry, [])\n",
    "                a.append(question_ids_map[question])\n",
    "                track_leafs[prev_node_entry] = a\n",
    "                G.add_edge(prev_node_entry, \" \".join(tokenized[:i]))\n",
    "                prev_node_entry =  \" \".join(tokenized[:i])\n",
    "            a = track_leafs.get(question, [])\n",
    "            a.append(question_ids_map[question])\n",
    "            track_leafs[question] = a\n",
    "\n",
    "roots_list = [i for i,j in G.nodes(data=\"starts\", default=1) if j==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx.write_gpickle(G, \"../index/v2/query_graph.gpickle\")\n",
    "# pickle.dump(track_leafs, open(\"../index/v2/track_leafs.pkl\", \"wb\"))\n",
    "# pickle.dump(ids_question_map, open(\"../index/v2/ids_question_map.pkl\", \"wb\"))\n",
    "# pickle.dump(question_ids_map, open(\"../index/v2/question_ids_map.pkl\", \"wb\"))\n",
    "\n",
    "G = nx.read_gpickle(\"../index/v2/query_graph.gpickle\")\n",
    "track_leafs = pickle.load(open(\"../index/v2/track_leafs.pkl\", \"rb\"))\n",
    "ids_question_map = pickle.load(open(\"../index/v2/ids_question_map.pkl\", \"rb\"))\n",
    "question_ids_map = pickle.load(open(\"../index/v2/question_ids_map.pkl\", \"rb\"))\n",
    "\n",
    "roots_list = [i for i,j in G.nodes(data=\"starts\", default=1) if j==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken:  0.038735168000130216\n"
     ]
    }
   ],
   "source": [
    "# recursion\n",
    "import timeit\n",
    "\n",
    "\n",
    "#query = \"do parents\".lower()\n",
    "query = \"what is presentation\".lower()\n",
    "#query = \"becoming a\".lower() # for v1 v2 comparison\n",
    "#query = \"hwat ia the\".lower()\n",
    "#query = \"what was the name given to a\".lower()\n",
    "#query = \"bbilical defn\".lower()\n",
    "#query = \"what\".lower()\n",
    "tokenized_query = query.split()\n",
    "len_tokenized_query = len(tokenized_query)\n",
    "node_list = []\n",
    "def recurssive_search(comparison_term, G, idx=1, root=False, node_list=[], forked=False):\n",
    "    new_term = []\n",
    "    for node in (roots_list if root else G[\" \".join(comparison_term.split()[:-1])]):\n",
    "        \n",
    "        # don't auto-correct on last-word\n",
    "        if ((ln.distance(comparison_term, node) <= 2) if idx!=len_tokenized_query-1 else tokenized_query[-1] in node):\n",
    "            if idx!=len_tokenized_query-1:\n",
    "                node_list.extend(recurssive_search(node + \" \" + tokenized_query[idx+1], G, idx+1, root=False, node_list=node_list, forked=True))\n",
    "            else:\n",
    "                if node in G and node in track_leafs:\n",
    "                    new_term.append(node)\n",
    "\n",
    "              \n",
    "    if forked:\n",
    "        if idx==len_tokenized_query-1:\n",
    "            return [ids_question_map[child] for term in new_term for child in track_leafs[term]]\n",
    "            \n",
    "        return \"\"\n",
    "    else:\n",
    "        if len(tokenized_query)==1:\n",
    "            if idx==len_tokenized_query-1:\n",
    "                return [ids_question_map[child] for term in new_term for child in track_leafs[term]]\n",
    "        return node_list\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "res = recurssive_search(tokenized_query[0], G, idx=0, root=True)\n",
    "print(\"Total time taken: \", timeit.default_timer()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what is representation meaning',\n",
       " 'what is representation means',\n",
       " 'what is representation yahoo answers',\n",
       " 'what is representation in legal terms',\n",
       " 'what is representation mean',\n",
       " 'what is representation in the legal dictionary',\n",
       " 'what is representation means synonyms',\n",
       " 'what is representation in government',\n",
       " 'what is representation in law',\n",
       " 'what is representation',\n",
       " 'what is representation in english',\n",
       " 'what is representation in house of representatives based on population',\n",
       " 'what is representation in ece',\n",
       " 'what is representation',\n",
       " 'what is representation fees geneve',\n",
       " 'what is representations',\n",
       " 'what is presentation gi sample density',\n",
       " 'what is representational democracy',\n",
       " 'when is misrepresentation puffery']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['do parents influence baby eye color',\n",
       " 'do parents know what to do when their kid has a fever',\n",
       " 'do parents need to have a child for family leave',\n",
       " 'do parents go to their kids college orientation',\n",
       " \"do parents affect children's self esteem\",\n",
       " 'do parents of groom give them a gift',\n",
       " 'do parents count as immediate family']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ids_question_map[child] for child in track_leafs['do parents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seer",
   "language": "python",
   "name": "seer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
